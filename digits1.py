# -*- coding: utf-8 -*-
"""Digits1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lcu1EzB517qIB6AeArUARhTdu44_vgNx

# Using Tensorflow to Solve MNIST Digits Problem

The data can be downloaded [Here](https://www.kaggle.com/c/digit-recognizer/data).

## Importing Data and Required Libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf

# %matplotlib inline

train_df = pd.read_csv("train.csv")

train_imgs = train_df.drop(['label'], axis=1).values
train_labels = train_df['label'].values

"""## Spliting and Normalizing Data"""

trainX, testX, trainY, testY = train_test_split(train_imgs, train_labels, test_size=.2)

trainX = StandardScaler().fit_transform(trainX)
testX = StandardScaler().fit_transform(testX)

"""## Visualizing Data"""











first_image = np.array(trainX[0], dtype='float')
pixels = first_image.reshape((28, 28))
plt.imshow(pixels, cmap='gray')

"""## Creating DNN"""

n_inputs = trainX.shape[1]
n_hidden1 = 1000
n_hidden2 = 500
n_hidden3 = 100
n_outputs = 10 # There are 10 different digits (0 to 9).

X = tf.placeholder(tf.float32, shape=(None, n_inputs))
y = tf.placeholder(tf.int64, shape=(None))

with tf.name_scope("dnn"):
  hidden1 = tf.layers.dense(X, n_hidden1, tf.nn.elu)
  hidden2 = tf.layers.dense(hidden1, n_hidden2, tf.nn.elu)
  hidden3 = tf.layers.dense(hidden2, n_hidden3, tf.nn.elu)
  outputs = tf.layers.dense(hidden3, n_outputs)

with tf.name_scope("loss"):
  xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=outputs, labels=y)
  loss = tf.reduce_mean(xentropy)

with tf.name_scope("train"):
  train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss)

with tf.name_scope("eval"):
  correct = tf.nn.in_top_k(outputs, y, 1)
  accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))

init = tf.global_variables_initializer()
saver = tf.train.Saver()

"""## Training DNN"""

with tf.Session() as sess:
  epochs = []
  train_scores = []
  test_scores = []
  init.run()
  for i in range(1, 41):
    sess.run(train_op, feed_dict={X:trainX, y:trainY})
    print(i, accuracy.eval(feed_dict={X:trainX, y:trainY}), accuracy.eval(feed_dict={X:testX, y:testY}))

"""## Evaluating Model"""

train_acc, test_acc

"""## Conclusion

From here, you can take the .ckpt files, and do whatever you see fit.  You can make more predictions, you can use it in a contest, you can use it in real life, etc.
"""